# -*- coding: utf-8 -*-
"""rockpaperscissors.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Xa1ycafRUBiNbbqshpWbS2uCYiQCm1_m
"""

# Commented out IPython magic to ensure Python compatibility.
# Mengimpor pustaka/modul python yang dibutuhkan
import zipfile
import os
import glob 
import warnings

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Dense, Flatten
from tensorflow.keras.layers import Dropout
from tensorflow.keras.optimizers import Adam
import tensorflow as tf

from keras.preprocessing import image
from google.colab import files
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline

!pip install -q kaggle

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!ls ~/.kaggle

!kaggle datasets download -d drgfreeman/rockpaperscissors

!mkdir datasets
!unzip -qq rockpaperscissors.zip -d dataset
!ls dataset

import os

dataset = os.path.join('/content/dataset')

print(os.listdir(dataset))

data = ['paper', 'scissors', 'rock']

for data in data:
    print(f'{data} images: ', len(os.listdir(f'/content/dataset/{data}')))

    total_image = len(list(glob.iglob("/content/dataset/*/*.*", recursive=True)))
print("Total Data Image JPEG     : ",total_image)

import shutil
base_dir = '/content/dataset/'
shutil.rmtree(os.path.join(base_dir, 'rps-cv-images'))
os.remove(os.path.join(base_dir, 'README_rpc-cv-images.txt'))

base_dir = '/content/dataset/'
train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'val')

datagen = ImageDataGenerator(
                    rescale=1./255,
                    rotation_range=30,
                    width_shift_range=0.2,
                    height_shift_range=0.2,
                    zoom_range=0.4,
                    shear_range = 0.2,
                    brightness_range = [0,1],
                    horizontal_flip=True,
                    vertical_flip= True,
                    fill_mode = 'nearest',
                    validation_split = 0.2) #membagi validation set 20%

train_generator = datagen.flow_from_directory(                           
	        base_dir,                                                                      
	        target_size=(150,150),                                                          
	        class_mode='categorical',                                                       
          shuffle=True,                                                                   
          subset='training'                                                              
          )

validation_generator = datagen.flow_from_directory(                      
	      base_dir,                                                                     
	      target_size=(150,150),                                                          
	      class_mode='categorical',                                                      
        shuffle=True,
        subset='validation'                                                            
        )

model = tf.keras.models.Sequential([
  tf.keras.layers.Conv2D(32, (3,3), activation = 'relu', input_shape= (150,150,3)),
  tf.keras.layers.MaxPooling2D(2,2),
  tf.keras.layers.Conv2D(64,(3,3), activation= 'relu'),
  tf.keras.layers.MaxPooling2D(2,2),
  tf.keras.layers.Conv2D(128,(3,3), activation= 'relu'),
  tf.keras.layers.MaxPooling2D(2,2),
  tf.keras.layers.Conv2D(256,(3,3), activation= 'relu'),
  tf.keras.layers.MaxPooling2D(2,2),
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(512, activation= 'relu'),
  tf.keras.layers.Dropout(0.1),                                                  #menambahkan dropout
  tf.keras.layers.Dense(3, activation= 'softmax')
])

model.compile(
    optimizer='adam', 
    loss='categorical_crossentropy', 
    metrics=['accuracy'])

def scheduler(epoch, lr):
  if epoch < 5:
    return lr
  else:
    return lr * tf.math.exp(-0.1)

lr_schedule = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose=1)
tb_callback = tf.keras.callbacks.TensorBoard(
    log_dir='logs', histogram_freq=0, write_graph=True, write_images=False,
    update_freq='epoch', embeddings_freq=0,
    embeddings_metadata=None
)

model.summary()

history = model.fit(
    train_generator,
    steps_per_epoch = 25,
    epochs = 25,
    validation_data = validation_generator,
    validation_steps = 5,
    verbose =2
)

import matplotlib.pyplot as plt
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'r', label='Akurasi Training ')                  
plt.plot(epochs, val_acc, 'b', label='Akurasi Validasi')
plt.title('Akurasi Training dan Validasi')
plt.legend(loc=0)
plt.figure()                                                                      
plt.show()

uploaded = files.upload()
from PIL import Image


for fn in uploaded.keys():

  path = fn 
  img = Image.open(path).resize((150, 150))
  imgplot = plt.imshow(img)
  x = np.array(img)
  x = np.expand_dims(x, axis=0)

  images = np.vstack([x])
  classes = model.predict(images, batch_size=10)

  print(fn)
  if classes[0,0]!=0:
    print('paper')
  elif classes[0,1]!=0:
    print('rock')
  else:
    print('scissors')

model.save('gfgModel.h5')
print('Model Saved!')
 
# load model
savedModel=load_model('gfgModel.h5')
savedModel.summary()

model.save_weights('gfgModelWeights')
print('Model Saved!')
 
# load model
savedModel = model.load_weights('gfgModelWeights')
print('Model Loaded!')